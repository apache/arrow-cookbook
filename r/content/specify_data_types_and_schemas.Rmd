# Defining Data Types

As discussed in previous chapters, Arrow automatically infers the most 
appropriate data type when reading in data or converting R objects to Arrow 
objects.  However, you might want to manually tell Arrow which data types to 
use, for example, to ensure interoperability with databases and data warehouse 
systems.  This chapter includes recipes for:

* changing the data types of existing Arrow objects
* defining data types during the process of creating Arrow objects

A table showing the default mappings between R and Arrow data types can be found 
in [R data type to Arrow data type mappings](#r2arrow).

A table containing Arrow data types, and their R equivalents can be found in 
[Arrow data type to R data type mapping](#arrow2r).

## Update the data type of an existing Arrow Array

You want to change the data type of an existing Arrow Array.

### Solution

```{r, cast_array}
# Create an Array to cast
integer_arr <- Array$create(1:5)

# Cast to an unsigned int8 type
uint_arr <- integer_arr$cast(target_type = uint8())

uint_arr
```

```{r, test_cast_array, opts.label = "test"}
test_that("cast_array works as expected", {
  expect_equal(
   uint_arr$type,
   uint8()
  )
})
```

### Discussion

There are some data types which are not compatible with each other. Errors will 
occur if you try to cast between incompatible data types.

```{r, incompat, eval = FALSE}
int_arr <- Array$create(1:5)
int_arr$cast(target_type = binary())
```

```{r}
## Error: NotImplemented: Unsupported cast from int32 to binary using function cast_binary
```

```{r, test_incompat, opts.label = "test"}
test_that("test_incompat works as expected", {
  expect_error(
    int_arr$cast(target_type = binary())
  )
})
```

## Update the data type of a field in an existing Arrow Table

You want to change the type of one or more fields in an existing Arrow Table.

### Solution

```{r, cast_table}
# Set up a tibble to use in this example
oscars <- tibble::tibble(
  actor = c("Katharine Hepburn", "Meryl Streep", "Jack Nicholson"),
  num_awards = c(4, 3, 3)
)

# Convert tibble to an Arrow table
oscars_arrow <- Table$create(oscars)

# The default mapping from numeric column "num_awards" is to a double
oscars_arrow

# Set up schema with "num_awards" as integer
oscars_schema <- schema(actor = string(), num_awards = int16())

# Cast to an int16
oscars_arrow_int <- oscars_arrow$cast(target_schema = oscars_schema)

oscars_arrow_int
```

```{r, test_cast_table, opts.label = "test"}
test_that("cast_table works as expected", {
  expect_equal(
    oscars_arrow_int$schema,
    schema(actor = string(), num_awards = int16())
  )
})
```

### Discussion {#no-compat-type}

There are some Arrow data types which do not have any R equivalent.  Attempting 
to cast to these data types or using a schema which contains them will result in
an error.

```{r, float_16_conversion, error=TRUE, eval=FALSE}
oscars <- tibble::tibble(
  actor = c("Katharine Hepburn", "Meryl Streep", "Jack Nicholson"),
  num_awards = c(4, 3, 3)
)

# Set up schema with "num_awards" as float16 which doesn't have an R equivalent
oscars_schema <- schema(actor = string(), num_awards = float16())

Table$create(oscars, schema = oscars_schema)

```

```{r}
## Error: Invalid: Cannot convert to Half Float
```

```{r, test_float_16_conversion, opts.label = "test"}
test_that("float_16_conversion works as expected", {
  expect_error(Table$create(oscars, schema = schema(actor = string(), num_awards = float16())))
})
```

## Specify data types when creating an Arrow table from an R object

You want to manually specify Arrow data types when converting an object from a data frame to an Arrow object.

### Solution

```{r, use_schema}
# Set up a tibble to use in this example
oscars <- tibble::tibble(
  actor = c("Katharine Hepburn", "Meryl Streep", "Jack Nicholson"),
  num_awards = c(4, 3, 3)
)

# Set up schema with "num_awards" as integer
oscars_schema <- schema(actor = string(), num_awards = int16())

# create arrow Table containing data and schema
oscars_data_arrow <- Table$create(oscars, schema = oscars_schema)

oscars_data_arrow
```
```{r, test_use_schema, opts.label = "test"}
test_that("use_schema works as expected", {
  expect_s3_class(oscars_data_arrow, "Table")
  expect_equal(
    oscars_data_arrow$schema,
    oscars_schema
  )
})
```

## Specify data types when reading in files

You want to manually specify Arrow data types when reading in files.

### Solution

```{r, use_schema_dataset}
# Set up a tibble to use in this example
oscars <- tibble::tibble(
  actor = c("Katharine Hepburn", "Meryl Streep", "Jack Nicholson"),
  num_awards = c(4, 3, 3)
)

# write dataset to disk
write_dataset(oscars, path = "oscars_data")

# Set up schema with "num_awards" as integer
oscars_schema <- schema(actor = string(), num_awards = int16())

# read the dataset in, using the schema instead of inferring the type automatically
oscars_dataset_arrow <- open_dataset("oscars_data", schema = oscars_schema)

oscars_dataset_arrow
```
```{r, test_use_schema_dataset, opts.label = "test"}
test_that("use_schema_dataset works as expected", {
  expect_s3_class(oscars_dataset_arrow, "Dataset")
  expect_equal(oscars_dataset_arrow$schema,
    oscars_schema
  )
})
```
```{r, include=FALSE}
unlink("oscars_data", recursive = TRUE)
```

## Combine and unify schemas

You have a dataset split across multiple sources for which you have separate 
schemas that you want to combine.

### Solution

You can use `unify_schemas()` to combine multiple schemas into a single schemas.

```{r, combine_schemas}
# create first schema to combine
country_code_schema <- schema(country = utf8(), code = utf8())

# create second schema to combine
country_location_schema <- schema(longitude = float32(), latitude = float32())

# combine schemas
combined_schemas <- unify_schemas(country_code_schema, country_location_schema)
combined_schemas
```

```{r, test_combine_schemas, opts.label = "test"}
test_that("combine_schemas works as expected", {
  expect_s3_class(combined_schemas, "Schema")
  expect_equal(combined_schemas,
    schema(country = utf8(), code = utf8(), longitude = float32(), latitude = float32())
  )
})
```


### Discussion

If you have two schemas containing fields with the same names and types, you can
 combine them into a single field.
 
```{r, combine_schemas_merge}
# create first schema to combine
country_code_schema <- schema(country = utf8(), code = utf8())

# create second schema to combine
country_phone_schema <- schema(country = utf8(), phone_prefix = int8())

# combine schemas
combined_schemas <- unify_schemas(country_code_schema, country_phone_schema)
combined_schemas
```

```{r, test_combine_schemas_merge, opts.label = "test", eval = FALSE}
test_that("combine_schemas_merge works as expected", {
  expect_s3_class(combined_schemas, "Schema")
  expect_equal(combined_schemas,
    schema(country = utf8(), code = utf8(), phone_prefix = int8())
  )
})
```

If you have schemas with the same names but different types, you will not be 
able to merge the schemas and will get an error.

```{r, combine_incompat_schemas, error = TRUE, eval = FALSE}
# create first schema to combine
country_code_schema <- schema(country = binary(), code = utf8())

# create second schema to combine
country_phone_schema <- schema(country = utf8(), phone_prefix = int8())

# combine schemas
unify_schemas(country_code_schema, country_phone_schema)
```

```{r}
## Error: Invalid: Unable to merge: Field country has incompatible types: binary vs string
```

```{r, test_combine_incompat_schemas, opts.label = "test"}
test_that("combine_incompat_schemas works as expected", {
  country_code_schema <- schema(country = binary(), code = utf8())
  country_phone_schema <- schema(country = utf8(), phone_prefix = int8())
  expect_error(unify_schemas(country_code_schema, country_phone_schema))
})
```
